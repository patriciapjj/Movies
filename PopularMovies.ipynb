{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "675c1163-0ec9-4263-b8d1-ee9690ab132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----------------------------+\n",
      "|movieID|count|movieTitle                   |\n",
      "+-------+-----+-----------------------------+\n",
      "|50     |583  |Star Wars (1977)             |\n",
      "|258    |509  |Contact (1997)               |\n",
      "|100    |508  |Fargo (1996)                 |\n",
      "|181    |507  |Return of the Jedi (1983)    |\n",
      "|294    |485  |Liar Liar (1997)             |\n",
      "|286    |481  |English Patient, The (1996)  |\n",
      "|288    |478  |Scream (1996)                |\n",
      "|1      |452  |Toy Story (1995)             |\n",
      "|300    |431  |Air Force One (1997)         |\n",
      "|121    |429  |Independence Day (ID4) (1996)|\n",
      "+-------+-----+-----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, LongType\n",
    "import codecs\n",
    "\n",
    "def load_movie_names():\n",
    "    \"\"\"\n",
    "    Load movie names from the u.ITEM file and return a dictionary mapping movie IDs to movie titles.\n",
    "    \"\"\"\n",
    "    movie_names = {}\n",
    "    # Specify the path to your u.ITEM file\n",
    "    with codecs.open(\"C:/SparkCourse/ml-100k/u.ITEM\", \"r\", encoding='ISO-8859-1', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            fields = line.split('|')\n",
    "            movie_names[int(fields[0])] = fields[1]\n",
    "    return movie_names\n",
    "\n",
    "def main():\n",
    "    # Initialize Spark session\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"PopularMovies\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Broadcast the movie names dictionary\n",
    "    name_dict = spark.sparkContext.broadcast(load_movie_names())\n",
    "\n",
    "    # Define schema for the u.data file\n",
    "    schema = StructType([\n",
    "        StructField(\"userID\", IntegerType(), True),\n",
    "        StructField(\"movieID\", IntegerType(), True),\n",
    "        StructField(\"rating\", IntegerType(), True),\n",
    "        StructField(\"timestamp\", LongType(), True)\n",
    "    ])\n",
    "\n",
    "    # Load movie data as a DataFrame\n",
    "    movies_df = spark.read \\\n",
    "        .option(\"sep\", \"\\t\") \\\n",
    "        .schema(schema) \\\n",
    "        .csv(\"file:///SparkCourse/ml-100k/u.data\")\n",
    "\n",
    "    # Group by movieID and count occurrences\n",
    "    movie_counts = movies_df.groupBy(\"movieID\").count()\n",
    "\n",
    "    # User-defined function to look up movie names\n",
    "    def lookup_name(movie_id):\n",
    "        return name_dict.value.get(movie_id, \"Unknown\")\n",
    "\n",
    "    # Register the UDF\n",
    "    lookup_name_udf = functions.udf(lookup_name)\n",
    "\n",
    "    # Add a movieTitle column using the UDF\n",
    "    movies_with_names = movie_counts.withColumn(\"movie\", lookup_name_udf(functions.col(\"movieID\")))\n",
    "\n",
    "    # Sort the results by count in descending order\n",
    "    sorted_movies_with_names = movies_with_names.orderBy(functions.desc(\"count\"))\n",
    "\n",
    "    # Show the top 10 most popular movies\n",
    "    sorted_movies_with_names.show(10, truncate=False)\n",
    "\n",
    "    # Stop the Spark session\n",
    "    spark.stop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "506e0dc0-3f87-492d-a38a-8b3ddd28d63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|cust_id|total_spent|\n",
      "+-------+-----------+\n",
      "|     45|    3309.38|\n",
      "|     79|    3790.57|\n",
      "|     96|    3924.23|\n",
      "|     23|    4042.65|\n",
      "|     99|    4172.29|\n",
      "|     75|     4178.5|\n",
      "|     36|    4278.05|\n",
      "|     98|    4297.26|\n",
      "|     47|     4316.3|\n",
      "|     77|    4327.73|\n",
      "|     13|    4367.62|\n",
      "|     48|    4384.33|\n",
      "|     49|     4394.6|\n",
      "|     94|    4475.57|\n",
      "|     67|    4505.79|\n",
      "|     50|    4517.27|\n",
      "|     78|    4524.51|\n",
      "|      5|    4561.07|\n",
      "|     57|     4628.4|\n",
      "|     83|     4635.8|\n",
      "|     91|    4642.26|\n",
      "|     74|    4647.13|\n",
      "|     84|    4652.94|\n",
      "|      3|    4659.63|\n",
      "|     12|    4664.59|\n",
      "|     66|    4681.92|\n",
      "|     56|    4701.02|\n",
      "|     21|    4707.41|\n",
      "|     80|    4727.86|\n",
      "|     14|    4735.03|\n",
      "|     37|     4735.2|\n",
      "|      7|    4755.07|\n",
      "|     44|    4756.89|\n",
      "|     31|    4765.05|\n",
      "|     82|    4812.49|\n",
      "|      4|    4815.05|\n",
      "|     10|     4819.7|\n",
      "|     88|    4830.55|\n",
      "|     20|    4836.86|\n",
      "|     89|    4851.48|\n",
      "|     95|    4876.84|\n",
      "|     38|    4898.46|\n",
      "|     76|    4904.21|\n",
      "|     86|    4908.81|\n",
      "|     27|    4915.89|\n",
      "|     18|    4921.27|\n",
      "|     53|     4945.3|\n",
      "|      1|     4958.6|\n",
      "|     51|    4975.22|\n",
      "|     16|    4979.06|\n",
      "|     30|    4990.72|\n",
      "|     28|    5000.71|\n",
      "|     22|    5019.45|\n",
      "|     29|    5032.53|\n",
      "|     17|    5032.68|\n",
      "|     60|    5040.71|\n",
      "|     25|    5057.61|\n",
      "|     19|    5059.43|\n",
      "|     81|    5112.71|\n",
      "|     69|    5123.01|\n",
      "|     65|    5140.35|\n",
      "|     11|    5152.29|\n",
      "|     35|    5155.42|\n",
      "|     40|    5186.43|\n",
      "|     87|     5206.4|\n",
      "|     52|    5245.06|\n",
      "|     26|     5250.4|\n",
      "|     62|    5253.32|\n",
      "|     33|    5254.66|\n",
      "|     24|    5259.92|\n",
      "|     93|    5265.75|\n",
      "|     64|    5288.69|\n",
      "|     90|    5290.41|\n",
      "|     55|    5298.09|\n",
      "|      9|    5322.65|\n",
      "|     34|     5330.8|\n",
      "|     72|    5337.44|\n",
      "|     70|    5368.25|\n",
      "|     43|    5368.83|\n",
      "|     92|    5379.28|\n",
      "|      6|    5397.88|\n",
      "|     15|    5413.51|\n",
      "|     63|    5415.15|\n",
      "|     58|    5437.73|\n",
      "|     32|    5496.05|\n",
      "|     61|    5497.48|\n",
      "|     85|    5503.43|\n",
      "|      8|    5517.24|\n",
      "|      0|    5524.95|\n",
      "|     41|    5637.62|\n",
      "|     59|    5642.89|\n",
      "|     42|    5696.84|\n",
      "|     46|    5963.11|\n",
      "|     97|    5977.19|\n",
      "|      2|    5994.59|\n",
      "|     71|    5995.66|\n",
      "|     54|    6065.39|\n",
      "|     39|    6193.11|\n",
      "|     73|     6206.2|\n",
      "|     68|    6375.45|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implement Total Spent by Customer with DataFrames\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"TotalSpentByCustomer\").master(\"local[*]\").getOrCreate()\n",
    "\n",
    "# Create schema when reading customer-orders\n",
    "customerOrderSchema = StructType([ \\\n",
    "                                  StructField(\"cust_id\", IntegerType(), True),\n",
    "                                  StructField(\"item_id\", IntegerType(), True),\n",
    "                                  StructField(\"amount_spent\", FloatType(), True)\n",
    "                                  ])\n",
    "\n",
    "# Load up the data into spark dataset\n",
    "customersDF = spark.read.schema(customerOrderSchema).csv(\"file:///Spark/customer-orders.csv\")\n",
    "\n",
    "totalByCustomer = customersDF.groupBy(\"cust_id\").agg(func.round(func.sum(\"amount_spent\"), 2) \\\n",
    "                                      .alias(\"total_spent\"))\n",
    "\n",
    "totalByCustomerSorted = totalByCustomer.sort(\"total_spent\")\n",
    "\n",
    "totalByCustomerSorted.show(totalByCustomerSorted.count())\n",
    "\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6cd8f4-aa51-4573-bc7d-6091379b559b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
